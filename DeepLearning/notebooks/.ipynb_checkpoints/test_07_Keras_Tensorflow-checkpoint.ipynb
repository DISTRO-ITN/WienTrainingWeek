{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this placeholder will contain our input digits, as flat vectors\n",
    "img = tf.placeholder(tf.float32, shape=(None, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "\n",
    "# Keras layers can be called on TensorFlow tensors:\n",
    "x = Dense(128, activation='relu')(img)  # fully-connected layer with 128 units and ReLU activation\n",
    "x = Dense(128, activation='relu')(x)\n",
    "preds = Dense(10, activation='softmax')(x)  # output layer with 10 units and a softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = tf.placeholder(tf.float32, shape=(None, 10))\n",
    "\n",
    "from keras.objectives import categorical_crossentropy\n",
    "loss = tf.reduce_mean(categorical_crossentropy(labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist_data = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "# Initialize all variables\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess.run(init_op)\n",
    "\n",
    "# Run training loop\n",
    "with sess.as_default():\n",
    "    for i in range(100):\n",
    "        batch = mnist_data.train.next_batch(50)\n",
    "        train_step.run(feed_dict={img: batch[0],\n",
    "                                  labels: batch[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1. ...,  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "from keras.metrics import categorical_accuracy as accuracy\n",
    "\n",
    "acc_value = accuracy(labels, preds)\n",
    "with sess.as_default():\n",
    "    print( acc_value.eval(feed_dict={img: mnist_data.test.images,\n",
    "                                    labels: mnist_data.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Different behaviors during training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "print K.learning_phase()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# train mode\n",
    "train_step.run(feed_dict={x: batch[0], labels: batch[1], K.learning_phase(): 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "img = tf.placeholder(tf.float32, shape=(None, 784))\n",
    "labels = tf.placeholder(tf.float32, shape=(None, 10))\n",
    "\n",
    "x = Dense(128, activation='relu')(img)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "preds = Dense(10, activation='softmax')(x)\n",
    "\n",
    "loss = tf.reduce_mean(categorical_crossentropy(labels, preds))\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "with sess.as_default():\n",
    "    for i in range(100):\n",
    "        batch = mnist_data.train.next_batch(50)\n",
    "        train_step.run(feed_dict={img: batch[0],\n",
    "                                  labels: batch[1],\n",
    "                                  K.learning_phase(): 1})\n",
    "\n",
    "acc_value = accuracy(labels, preds)\n",
    "with sess.as_default():\n",
    "    print acc_value.eval(feed_dict={img: mnist_data.test.images,\n",
    "                                    labels: mnist_data.test.labels,\n",
    "                                    K.learning_phase(): 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compatibility with name scopes, device scopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=(None, 20, 64))\n",
    "with tf.name_scope('block1'):\n",
    "    y = LSTM(32, name='mylstm')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    x = tf.placeholder(tf.float32, shape=(None, 20, 64))\n",
    "    y = LSTM(32)(x)  # all ops / variables in the LSTM layer will live on GPU:0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compatibility with graph scopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import LSTM\n",
    "import tensorflow as tf\n",
    "\n",
    "my_graph = tf.Graph()\n",
    "with my_graph.as_default():\n",
    "    x = tf.placeholder(tf.float32, shape=(None, 20, 64))\n",
    "    y = LSTM(32)(x)  # all ops / variables in the LSTM layer are created as part of our graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compatibility with variable scopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LSTM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-79698a09477c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# instantiate a Keras layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlstm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# instantiate two TF placeholders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LSTM' is not defined"
     ]
    }
   ],
   "source": [
    "# instantiate a Keras layer\n",
    "lstm = LSTM(32)\n",
    "\n",
    "# instantiate two TF placeholders\n",
    "x = tf.placeholder(tf.float32, shape=(None, 20, 64))\n",
    "y = tf.placeholder(tf.float32, shape=(None, 20, 64))\n",
    "\n",
    "# encode the two tensors with the *same* LSTM weights\n",
    "x_encoded = lstm(x)\n",
    "y_encoded = lstm(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting trainable weights and state updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization\n",
    "\n",
    "layer = BatchNormalization()(x)\n",
    "\n",
    "update_ops = []\n",
    "for old_value, new_value in layer.updates:\n",
    "    update_ops.append(tf.assign(old_value, new_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "\n",
    "layer = Dense(32)(x)  # instantiate and call a layer\n",
    "print layer.trainable_weights  # list of TensorFlow Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Keras models with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting a Keras Sequential model for use in a TensorFlow workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is our initial Keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=784))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import InputLayer\n",
    "\n",
    "# this is our modified Keras model\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_tensor=custom_input_tensor,\n",
    "                     input_shape=(None, 784)))\n",
    "\n",
    "# build the rest of the model as before\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.load_weights(weights_file) \n",
    "\n",
    "output_tensor = model.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calling a Keras model on a TensorFlow tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=784))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# this works! \n",
    "x = tf.placeholder(tf.float32, shape=(None, 784))\n",
    "y = model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-GPU and distributed training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    x = tf.placeholder(tf.float32, shape=(None, 784))\n",
    "\n",
    "    # shared model living on CPU:0\n",
    "    # it won't actually be run during training; it acts as an op template\n",
    "    # and as a repository for shared variables\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, activation='relu', input_dim=784))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# replica 0\n",
    "with tf.device('/gpu:0'):\n",
    "    output_0 = model(x)  # all ops in the replica will live on GPU:0\n",
    "\n",
    "# replica 1\n",
    "with tf.device('/gpu:1'):\n",
    "    output_1 = model(x)  # all ops in the replica will live on GPU:1\n",
    "\n",
    "# merge outputs on CPU\n",
    "with tf.device('/cpu:0'):\n",
    "    preds = 0.5 * (output_0 + output_1)\n",
    "\n",
    "# we only run the `preds` tensor, so that only the two\n",
    "# replicas on GPU get run (plus the merge op on CPU)\n",
    "output_value = sess.run([preds], feed_dict={x: data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "server = tf.train.Server.create_local_server()\n",
    "sess = tf.Session(server.target)\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting a model with TensorFlow-serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "K.set_learning_phase(0)  # all new operations will be in test mode from now on\n",
    "\n",
    "# serialize the model and get its weights, for quick re-building\n",
    "config = previous_model.get_config()\n",
    "weights = previous_model.get_weights()\n",
    "\n",
    "# re-build a model where the learning phase is now hard-coded to 0\n",
    "from keras.models import model_from_config\n",
    "new_model = model_from_config(config)\n",
    "new_model.set_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow_serving.session_bundle import exporter\n",
    "\n",
    "export_path = ... # where to save the exported graph\n",
    "export_version = ... # version number (integer)\n",
    "\n",
    "saver = tf.train.Saver(sharded=True)\n",
    "model_exporter = exporter.Exporter(saver)\n",
    "signature = exporter.classification_signature(input_tensor=model.input,\n",
    "                                              scores_tensor=model.output)\n",
    "model_exporter.init(sess.graph.as_graph_def(),\n",
    "                    default_graph_signature=signature)\n",
    "model_exporter.export(export_path, tf.constant(export_version), sess)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
